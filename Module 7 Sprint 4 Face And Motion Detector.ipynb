{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import pandas\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture frames from a camera \n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop runs if capturing has been initialized. \n",
    "while True:  \n",
    "    # reads frames from a camera \n",
    "    ret, img = cap.read()  \n",
    "  \n",
    "    # convert to gray scale of each frames \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Detects faces of different sizes in the input image \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
    "  \n",
    "    for (x,y,w,h) in faces: \n",
    "        # To draw a rectangle in a face  \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)  \n",
    "        roi_gray = gray[y:y+h, x:x+w] \n",
    "        roi_color = img[y:y+h, x:x+w] \n",
    "  \n",
    "        # Detects eyes of different sizes in the input image \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)  \n",
    "  \n",
    "        #To draw a rectangle in eyes \n",
    "        for (ex,ey,ew,eh) in eyes: \n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2) \n",
    "  \n",
    "    # Display an image in a window \n",
    "    cv2.imshow('img',img) \n",
    "  \n",
    "    # Wait for Esc key to stop \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: \n",
    "        break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the window \n",
    "cap.release() \n",
    "  \n",
    "# De-allocate any associated memory usage \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion Detector\n",
    "# Assigning our static_back to None \n",
    "static_back = None\n",
    "  \n",
    "# List when any moving object appear \n",
    "motion_list = [ None, None ] \n",
    "  \n",
    "# Time of movement \n",
    "time = [] \n",
    "  \n",
    "# Initializing DataFrame, one column is start  \n",
    "# time and other column is end time \n",
    "df = pandas.DataFrame(columns = [\"Start\", \"End\"]) \n",
    "  \n",
    "# Capturing video \n",
    "video = cv2.VideoCapture(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infinite while loop to treat stack of image as video \n",
    "while True: \n",
    "    # Reading frame(image) from video \n",
    "    check, frame = video.read() \n",
    "  \n",
    "    # Initializing motion = 0(no motion) \n",
    "    motion = 0\n",
    "  \n",
    "    # Converting color image to gray_scale image \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Converting gray scale image to GaussianBlur  \n",
    "    # so that change can be find easily \n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0) \n",
    "    \n",
    "    # In first iteration we assign the value  \n",
    "    # of static_back to our first frame \n",
    "    if static_back is None: \n",
    "        static_back = gray \n",
    "        continue\n",
    "  \n",
    "    # Difference between static background  \n",
    "    # and current frame(which is GaussianBlur) \n",
    "    diff_frame = cv2.absdiff(static_back, gray) \n",
    "  \n",
    "    # If change in between static background and \n",
    "    # current frame is greater than 30 it will show white color(255) \n",
    "    thresh_frame = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)[1] \n",
    "    thresh_frame = cv2.dilate(thresh_frame, None, iterations = 2) \n",
    "  \n",
    "    # Finding contour of moving object \n",
    "    cnts,_ = cv2.findContours(thresh_frame.copy(),  \n",
    "                       cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in cnts: \n",
    "        if cv2.contourArea(contour) < 10000: \n",
    "            continue\n",
    "        motion = 1\n",
    "  \n",
    "        (x, y, w, h) = cv2.boundingRect(contour) \n",
    "        # making green rectangle arround the moving object \n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3) \n",
    "  \n",
    "    # Appending status of motion \n",
    "    motion_list.append(motion) \n",
    "  \n",
    "    motion_list = motion_list[-2:] \n",
    "  \n",
    "    # Appending Start time of motion \n",
    "    if motion_list[-1] == 1 and motion_list[-2] == 0: \n",
    "        time.append(datetime.now())\n",
    "    \n",
    "    # Appending End time of motion \n",
    "    if motion_list[-1] == 0 and motion_list[-2] == 1: \n",
    "        time.append(datetime.now()) \n",
    "  \n",
    "    # Displaying image in gray_scale \n",
    "    cv2.imshow(\"Gray Frame\", gray) \n",
    "  \n",
    "    # Displaying the difference in currentframe to \n",
    "    # the staticframe(very first_frame) \n",
    "    cv2.imshow(\"Difference Frame\", diff_frame) \n",
    "  \n",
    "    # Displaying the black and white image in which if \n",
    "    # intensity difference greater than 30 it will appear white \n",
    "    cv2.imshow(\"Threshold Frame\", thresh_frame) \n",
    "  \n",
    "    # Displaying color frame with contour of motion of object \n",
    "    cv2.imshow(\"Color Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) \n",
    "    # if q entered whole process will stop \n",
    "    if key == ord('q'): \n",
    "        # if something is movingthen it append the end time of movement \n",
    "        if motion == 1: \n",
    "            time.append(datetime.now()) \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(time), 2): \n",
    "    df = df.append({\"Start\":time[i], \"End\":time[i + 1]}, ignore_index = True) \n",
    "  \n",
    "# Creating a CSV file in which time of movements will be saved \n",
    "df.to_csv(\"CountsOfMovements.csv\") \n",
    "  \n",
    "video.release() \n",
    "  \n",
    "# Destroying all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
